# Recall AI Case Study

Michael Siega, mf.siega@gmail.com, 2024-11-26

## Prompt

Create a chat application that allows users to interact with a dataset of video summaries.

## tl;dr

If you just want some pointers to quickly review what I've done:

- `backend/src/main.py` is the entrypoint to the server. Most of the code lives in that directory.
- `backend/preprocessing` has some scripts that I used to generate e.g., embeddings for the summaries.
- `frontend/case-study-chat/src/app/page.tsx` has the actual frontend, but it's very minimal.

## To run locally

### Prerequisites

- Docker
- An OpenAI API key

NOTE: I've bundled the preprocessed data e.g., embeddings in the `backend/data` directory for convenience.

### Steps

1. Check out the repository
2. Go into the `backend` directory, run `docker build -t chat-api-server .`
3. Run `docker run -e OPENAI_API_KEY=<key> -d -p 8000:8000 chat-api-server`
4. Go into the `frontend/case-study-chat` directory, run `docker build -t chat-frontend .`
5. Run `docker run -p 3000:3000 chat-frontend`
6. Access the app at `localhost:3000`

## Approach

There are three main components to the codebase:

- Frontend, to present the chat interface.
- Backend, to handle chat queries about the dataset.
- Preprocessing, to generate initial context to serve requests.

An overview of these components below.

### Preprocessing

To efficiently serve queries based on the dataset, we take some preprocessing steps:

1. Generate embeddings for the summaries. This will support semantic search for incoming queries.
2. Entity extraction for the summaries. This will allow us to efficiently find related entities and summaries for the queries.

The code lives in `backend/preprocessing`. The output has been placed in `backend/data`.

#### Embeddings

We use the `text-embedding-ada-002` model in the OpenAI API to generate embeddings for each summary.

#### Entity extraction

For quick development, we use the `gpt-4o-mini` model in the OpenAI API and a crafted prompt to generate important entities and topics for each summary.

#### Data storage

We store both the embeddings and the entity data in serialized JSON. At runtime, the server loads the JSON and does whatever processing necessary to make it usable (more below).

In a larger-scale system, this would all live in a database rather than being hydrated at runtime by the server; either a specialized database like Neo4j or simply represented in a relational database.

### Frontend

This is a super simple NextJS app, via `create-next-app`. The code itself was largely generated by ChatGPT with some tweaks - bugfixes in the generated code, adding `ReactMarkdown` support.

### Backend

The API is implemented in Python, for ease of interacting with the various AI-related tooling. FastAPI is used to expose the endpoints. The main request handling is in `backend/src/server.py`. Significant components are broken out:

- `build_entity_graph` to do the runtime loading of topics and entities into a graph representation.
- `RelatedSummaryFinder` to identify the summaries most closely related to the query.
- `AnswerGenerator` to generate the actual answer to the question.
- `RelatedTopicGenerator` to identify topics and entities from the answer for further reading.

#### High-level description

At a high level, this is how a question is handled:

- We get the embedding for the query, and use Facebook AI Similarity Search (FAISS) to identify the top-5 related summaries.
- We send the query to the OpenAI API, along with the related summaries for context.
- We send the answer _back_ to the OpenAI API, along with the topics and entities in our entity graph, and ask it to identify some topics and entities that are most relevant.
- For each of these, we find the summaries that include them via the graph.
- The answer is returned to the user, along with the topics/entities/related summaries.

## Notes and future work

See the [Github issues](https://github.com/mfsiega/recall-case-study/issues) for future work. Some of these are small clear improvements, others are alternative approaches that I would want to try.

The code is very much in a state of `initial-proof-of-concept`. Those issues cover some of the things I'd want to consider before shipping something like this (especially the ones labeled `usability`).
